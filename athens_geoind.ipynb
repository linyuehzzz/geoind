{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "gdf = gpd.read_file('data/athens/athens_households_all.shp')\n",
    "cnt = int(len(gdf) * 0.01)\n",
    "sample = gdf.sample(n=cnt)\n",
    "sample.to_file('data/athens/athens_sample.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "gdf1 = gpd.read_file('data/athens/athens_sample.shp')\n",
    "gdf2 = gpd.read_file('data/athens/athens_households_all.shp')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[38173, 38174, 38175, ..., 38267, 38226, 38259],\n",
       "        [10161, 10160, 10134, ..., 10036, 10136, 10038],\n",
       "        [45508, 45507, 45509, ..., 45518, 51693, 51709],\n",
       "        ...,\n",
       "        [45264, 45265, 45266, ..., 45383, 53661, 53662],\n",
       "        [28932, 28930, 28931, ..., 28077, 29015, 28923],\n",
       "        [52744, 52745, 52746, ..., 52707, 48039, 52501]], dtype=int64),\n",
       " array([[0.00000000e+00, 5.30177671e+00, 1.25963889e+01, ...,\n",
       "         1.17816084e+02, 1.21382277e+02, 1.23457408e+02],\n",
       "        [0.00000000e+00, 7.60730729e+02, 9.05900725e+02, ...,\n",
       "         1.20915686e+03, 1.21884277e+03, 1.22533563e+03],\n",
       "        [0.00000000e+00, 6.51904793e-01, 1.35909445e+00, ...,\n",
       "         2.25150495e+02, 2.32561223e+02, 2.33339931e+02],\n",
       "        ...,\n",
       "        [0.00000000e+00, 4.06265056e+01, 1.21635033e+02, ...,\n",
       "         9.82553673e+02, 9.85673862e+02, 9.89192531e+02],\n",
       "        [0.00000000e+00, 2.37940958e+01, 2.64381857e+01, ...,\n",
       "         1.38149606e+02, 1.42737377e+02, 1.42851579e+02],\n",
       "        [0.00000000e+00, 1.82007736e+02, 1.98106808e+02, ...,\n",
       "         9.69320468e+02, 9.72732057e+02, 9.77949547e+02]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import BallTree\n",
    "import pickle\n",
    "\n",
    "k_neighbors = 31\n",
    "def get_nearest(src_points, candidates, k_neighbors=10):\n",
    "    \"\"\"\n",
    "    Find nearest neighbors for all source points from a set of candidate points\n",
    "    modified from: https://automating-gis-processes.github.io/site/notebooks/L3/nearest-neighbor-faster.html\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create tree from the candidate points\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='euclidean')\n",
    "\n",
    "    # Find closest points and distances\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "\n",
    "    # Return indices and distances\n",
    "    return indices, distances\n",
    "\n",
    "in_pts = [(x,y) for x,y in zip(gdf1.geometry.x , gdf1.geometry.y)]\n",
    "qry_pts =  [(x,y) for x,y in zip(gdf2.geometry.x , gdf2.geometry.y)]\n",
    "X, X_dis = get_nearest(in_pts, qry_pts, k_neighbors)\n",
    "pickle.dump(X, open('data/athens/athens_buff_k' + str(k_neighbors-1) + '.pickle', \"wb\"))\n",
    "pickle.dump(X_dis, open('data/athens/athens_buff_dis_k' + str(k_neighbors-1) + '.pickle', \"wb\"))\n",
    "\n",
    "X, X_dis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparative analysis with lwized location swapping\n",
    "\n",
    "(1) Expected distance displaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rp_edd(buffer_dis):\n",
    "    edd_rp = []\n",
    "    for row in buffer_dis:\n",
    "        edd_rp.append(np.max(row) / 2)\n",
    "    return sum(edd_rp) / len(edd_rp)\n",
    "\n",
    "def lw_edd(buffer_dis):\n",
    "    edd_lw = []\n",
    "    for row in buffer_dis:\n",
    "        edd_lw.append(np.mean(row))\n",
    "    return sum(edd_lw) / len(edd_lw)\n",
    "\n",
    "def gm_edd(prob, buffer_dis):\n",
    "    edd_gm = []\n",
    "    for idx, row in prob.iterrows():\n",
    "        edd_gm.append(np.dot(buffer_dis[idx], row.tolist()))\n",
    "    return sum(edd_gm) / len(edd_gm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edd_rp: 158.89296334137825\n",
      "edd_lw: 199.2766049262771\n",
      "edd_gm: 56.737655736182866\n",
      "edd_gm: 85.96661427379287\n",
      "edd_gm: 144.2798627010939\n",
      "edd_gm: 190.87555534776905\n",
      "edd_rp: 256.2277676547883\n",
      "edd_lw: 314.50318584771634\n",
      "edd_gm: 50.42225015122305\n",
      "edd_gm: 98.45900255518676\n",
      "edd_gm: 206.08671342819423\n",
      "edd_gm: 266.17520697516204\n",
      "edd_rp: 327.73370091814206\n",
      "edd_lw: 407.3932246858109\n",
      "edd_gm: 43.15888507687288\n",
      "edd_gm: 106.37908982069176\n",
      "edd_gm: 261.0029093161786\n",
      "edd_gm: 300.12092786125265\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "k_neighbors_all = [10, 20, 30]\n",
    "eps_all = [0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "with open('data/athens/sols/athens_edd_all.csv', 'w') as fw:\n",
    "    fw.write('method,eps,k,edd\\n')\n",
    "    fw.flush()\n",
    "\n",
    "    for k_neighbors in k_neighbors_all:\n",
    "        buffer_dis = pickle.load(open('data/athens/athens_buff_dis_k' + str(k_neighbors) + '.pickle', \"rb\"))\n",
    "        buffer_dis = np.delete(buffer_dis, 0, 1)\n",
    "\n",
    "        # rp\n",
    "        edd_rp = rp_edd(buffer_dis)\n",
    "        fw.write('rp,,' + str(k_neighbors) + ',' + str(edd_rp) + '\\n')\n",
    "        print('edd_rp:', edd_rp)\n",
    "\n",
    "        # lw\n",
    "        edd_lw = lw_edd(buffer_dis)\n",
    "        fw.write('lw,,' + str(k_neighbors) + ',' + str(edd_lw) + '\\n')\n",
    "        print('edd_lw:', edd_lw)\n",
    "        \n",
    "        # gm\n",
    "        for eps in eps_all:\n",
    "            prob = pd.read_csv('data/athens/sols/athens_prob_eps' + str(eps) + \"_k\" + str(k_neighbors) + '.csv', header=None, index_col=0)\n",
    "            edd_gm = gm_edd(prob, buffer_dis)\n",
    "            fw.write('gm,' + str(eps) + ',' + str(k_neighbors) + ',' + str(edd_gm) + '\\n')\n",
    "            print('edd_gm:', edd_gm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Average nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pointpats import PointPattern\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def origin_ann(gdf):\n",
    "    points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "    pp = PointPattern(points)\n",
    "    return pp.mean_nnd\n",
    "\n",
    "\n",
    "def displace_point(point, max_dist):\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    distance = np.random.uniform(0, max_dist)\n",
    "    new_x = point.x + distance * np.cos(angle)\n",
    "    new_y = point.y + distance * np.sin(angle)\n",
    "    return Point(new_x, new_y)\n",
    "\n",
    "def rp_ann(gdf1, buffer_dis, ann_origin, T=100):\n",
    "    ann = []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        for idx, row in gdf1.iterrows():\n",
    "            point = row['geometry']\n",
    "            r = np.max(buffer_dis[idx])\n",
    "            x = displace_point(point, r)\n",
    "            masked_locs.append(x)\n",
    "        gdf = gpd.GeoDataFrame(geometry=masked_locs)\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        pp = PointPattern(points)\n",
    "        ann.append(pp.mean_nnd)\n",
    "    return sum(ann) / len(ann) - ann_origin\n",
    "\n",
    "\n",
    "def lw_ann(gdf2, buffer, ann_origin, T=100):\n",
    "    ann = []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        for locs in buffer:\n",
    "            locs = np.delete(locs, 0)\n",
    "            x = random.choice(locs)\n",
    "            masked_locs.append(x)\n",
    "        gdf = gdf2.iloc[masked_locs]\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        pp = PointPattern(points)\n",
    "        ann.append(pp.mean_nnd)\n",
    "    return sum(ann) / len(ann) - ann_origin\n",
    "\n",
    "\n",
    "def gm_ann(gdf2, prob, buffer, ann_origin, T=100):\n",
    "    ann = []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        for idx, row in prob.iterrows():\n",
    "            locs = buffer[idx]\n",
    "            locs = np.delete(locs, 0)\n",
    "            x = random.choices(locs, weights=tuple(row.tolist()), k=1)[0]\n",
    "            masked_locs.append(x)\n",
    "        gdf = gdf2.iloc[masked_locs]\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        pp = PointPattern(points)\n",
    "        ann.append(pp.mean_nnd)\n",
    "    return sum(ann) / len(ann) - ann_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_origin: 1167.7297504779806\n",
      "ann_rp: 5.933749469446639\n",
      "ann_lw: -25.934089358964684\n",
      "ann_gm: -17.20116407048431\n",
      "ann_gm: -5.7043514785473235\n",
      "ann_gm: -26.685245777430055\n",
      "ann_gm: -30.949900488492176\n",
      "ann_rp: 12.752462627398245\n",
      "ann_lw: -46.865773740329814\n",
      "ann_gm: -81.10288766415465\n",
      "ann_gm: -8.633459349164468\n",
      "ann_gm: -54.77013026750319\n",
      "ann_gm: -66.99885230985478\n",
      "ann_rp: 24.966414385531607\n",
      "ann_lw: -52.46828627669379\n",
      "ann_gm: -163.22992320285186\n",
      "ann_gm: -11.574822530457595\n",
      "ann_gm: -67.24107249954977\n",
      "ann_gm: -84.0296943783851\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "ann_origin = origin_ann(gdf1)\n",
    "print('ann_origin:', ann_origin)\n",
    "\n",
    "k_neighbors_all = [10, 20, 30]\n",
    "eps_all = [0.1, 0.01, 0.001, 0.0001]\n",
    "T = 100\n",
    "\n",
    "with open('data/athens/sols/athens_ann_all.csv', 'w') as fw:\n",
    "    fw.write('method,eps,k,ann\\n')\n",
    "    fw.write('origin,,' + str(ann_origin) + '\\n')\n",
    "    fw.flush()\n",
    "    \n",
    "    for k_neighbors in k_neighbors_all:\n",
    "        buffer = pickle.load(open('data/athens/athens_buff_k' + str(k_neighbors) + '.pickle', \"rb\"))\n",
    "        buffer_dis = pickle.load(open('data/athens/athens_buff_dis_k' + str(k_neighbors) + '.pickle', \"rb\"))\n",
    "        buffer_dis = np.delete(buffer_dis, 0, 1)\n",
    "        \n",
    "        # rp\n",
    "        ann_rp = rp_ann(gdf1, buffer_dis, ann_origin, T)\n",
    "        fw.write('rp,,' + str(k_neighbors) + ',' + str(ann_rp) + '\\n')\n",
    "        print('ann_rp:', ann_rp)\n",
    "\n",
    "        # lw\n",
    "        ann_lw = lw_ann(gdf2, buffer, ann_origin, T)\n",
    "        fw.write('lw,,' + str(k_neighbors) + ',' + str(ann_lw) + '\\n')\n",
    "        print('ann_lw:', ann_lw)\n",
    "        \n",
    "        # gm\n",
    "        for eps in eps_all:\n",
    "            prob = pd.read_csv('data/athens/sols/athens_prob_eps' + str(eps) + \"_k\" + str(k_neighbors) + '.csv', header=None, index_col=0)\n",
    "            ann_gm = gm_ann(gdf2, prob, buffer, ann_origin, T)\n",
    "            fw.write('gm,' + str(eps) + ',' + str(k_neighbors) + ',' + str(ann_gm) + '\\n')\n",
    "            print('ann_gm:', ann_gm)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Cluster detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated number of clusters: 0\n",
      "Estimated number of noise points: 569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "X = np.array(np.stack([gdf1.geometry.x, gdf1.geometry.y], axis=1))\n",
    "db = DBSCAN(eps=1000, min_samples=30).fit(X)\n",
    "labels = db.labels_\n",
    "gdf = gdf1.copy()\n",
    "gdf['db_origin'] = labels\n",
    "gdf.to_file('data/athens/athens_sample_db.shp')\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)\n",
    "\n",
    "print(\"Estimated number of clusters: %d\" % n_clusters_)\n",
    "print(\"Estimated number of noise points: %d\" % n_noise_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "def displace_point(point, max_dist):\n",
    "    angle = np.random.uniform(0, 2 * np.pi)\n",
    "    distance = np.random.uniform(0, max_dist)\n",
    "    new_x = point.x + distance * np.cos(angle)\n",
    "    new_y = point.y + distance * np.sin(angle)\n",
    "    return Point(new_x, new_y)\n",
    "\n",
    "def rp_db(gdf1, buffer_dis, labels, T=100):\n",
    "    precision_all, recall_all, f1_score_all = [], [], []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        for idx, row in gdf1.iterrows():\n",
    "            point = row['geometry']\n",
    "            r = np.max(buffer_dis[idx])\n",
    "            x = displace_point(point, r)\n",
    "            masked_locs.append(x)\n",
    "        gdf = gpd.GeoDataFrame(geometry=masked_locs)\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        db = DBSCAN(eps=500, min_samples=5).fit(points)\n",
    "        preds = db.labels_\n",
    "        preds_binary = [0 if i == -1 else 1 for i in preds]\n",
    "\n",
    "        precision = metrics.precision_score(labels, preds_binary, average='weighted')\n",
    "        recall = metrics.recall_score(labels, preds_binary, average='weighted')\n",
    "        f1_score = metrics.f1_score(labels, preds_binary, average='weighted')\n",
    "        precision_all.append(precision)\n",
    "        recall_all.append(recall)\n",
    "        f1_score_all.append(f1_score)\n",
    "    return sum(precision_all) / len(precision_all), sum(recall_all) / len(recall_all), sum(f1_score_all) / len(f1_score_all)\n",
    "\n",
    "    \n",
    "def lw_db(gdf2, buffer, labels, T=100):\n",
    "    precision_all, recall_all, f1_score_all = [], [], []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        for locs in buffer:\n",
    "            locs = np.delete(locs, 0)\n",
    "            x = random.choice(locs)\n",
    "            masked_locs.append(x)\n",
    "        gdf = gdf2.iloc[masked_locs]\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        db = DBSCAN(eps=500, min_samples=5).fit(points)\n",
    "        preds = db.labels_\n",
    "        preds_binary = [0 if i == -1 else 1 for i in preds]\n",
    "\n",
    "        precision = metrics.precision_score(labels, preds_binary, average='weighted')\n",
    "        recall = metrics.recall_score(labels, preds_binary, average='weighted')\n",
    "        f1_score = metrics.f1_score(labels, preds_binary, average='weighted')\n",
    "        precision_all.append(precision)\n",
    "        recall_all.append(recall)\n",
    "        f1_score_all.append(f1_score)\n",
    "    return sum(precision_all) / len(precision_all), sum(recall_all) / len(recall_all), sum(f1_score_all) / len(f1_score_all)\n",
    "\n",
    "\n",
    "def gm_db(gdf2, prob, buffer, labels, T=100):\n",
    "    precision_all, recall_all, f1_score_all = [], [], []\n",
    "    for t in range(T):\n",
    "        masked_locs = []\n",
    "        labels_all = []\n",
    "        for idx, row in prob.iterrows():\n",
    "            labels_all.append(labels[idx])\n",
    "            locs = buffer[idx]\n",
    "            locs = np.delete(locs, 0)\n",
    "            x = random.choices(locs, weights=tuple(row.tolist()), k=1)[0]\n",
    "            masked_locs.append(x)\n",
    "        gdf = gdf2.iloc[masked_locs]\n",
    "        points = np.array(np.stack([gdf.geometry.x, gdf.geometry.y], axis=1))\n",
    "        db = DBSCAN(eps=500, min_samples=5).fit(points)\n",
    "        preds = db.labels_\n",
    "        preds_binary = [0 if i == -1 else 1 for i in preds]\n",
    "\n",
    "        precision = metrics.precision_score(labels_all, preds_binary, average='weighted')\n",
    "        recall = metrics.recall_score(labels_all, preds_binary, average='weighted')\n",
    "        f1_score = metrics.f1_score(labels_all, preds_binary, average='weighted')\n",
    "        precision_all.append(precision)\n",
    "        recall_all.append(recall)\n",
    "        f1_score_all.append(f1_score)\n",
    "    return sum(precision_all) / len(precision_all), sum(recall_all) / len(recall_all), sum(f1_score_all) / len(f1_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "db_rp: 0.9858152014547001 0.9856414762741653 0.9856148842220694\n",
      "db_lw: 0.9812452836080736 0.9808084358523729 0.9808732118606879\n",
      "db_gm: 0.991335151515118 0.9909010600706719 0.9909861798090509\n",
      "db_gm: 0.9865288823904906 0.9858699472759234 0.9860204708842955\n",
      "db_gm: 0.9814811319126174 0.9807381370826007 0.9809141493197495\n",
      "db_gm: 0.9806271823468543 0.9801054481546572 0.980213665537031\n",
      "db_rp: 0.9792021785668328 0.9791036906854131 0.9789495913093392\n",
      "db_lw: 0.9755504809482572 0.9750439367311076 0.9751267498999758\n",
      "db_gm: 0.9904133256184682 0.9899259259259278 0.9900205099688663\n",
      "db_gm: 0.9877774539035071 0.9873813708260105 0.987475049273163\n",
      "db_gm: 0.9808074801803736 0.9798594024604574 0.9800878109906056\n",
      "db_gm: 0.975977468056443 0.9752372583479791 0.975388281402844\n",
      "db_rp: 0.9738689106472144 0.9737258347978909 0.9735549741782143\n",
      "db_lw: 0.9669484769385568 0.9657820738137087 0.966071562287719\n",
      "db_gm: 0.9893397252366105 0.9887751004016054 0.9888805893616365\n",
      "db_gm: 0.9818615313819662 0.9813005272407733 0.9814277185288762\n",
      "db_gm: 0.9778419694017252 0.9768541300527243 0.9771097831164187\n",
      "db_gm: 0.9697117594291239 0.9683655536028118 0.9686867810593468\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "X = np.array(np.stack([gdf1.geometry.x, gdf1.geometry.y], axis=1))\n",
    "db = DBSCAN(eps=500, min_samples=5).fit(X)\n",
    "labels = db.labels_\n",
    "labels_binary = [0 if i == -1 else 1 for i in labels]\n",
    "\n",
    "k_neighbors_all = [10, 20, 30]\n",
    "eps_all = [0.1, 0.01, 0.001, 0.0001]\n",
    "T = 100\n",
    "\n",
    "with open('data/athens/sols/athens_db_all.csv', 'w') as fw:\n",
    "    fw.write('method,eps,k,precision,recall,f1\\n')\n",
    "    fw.flush()\n",
    "    \n",
    "    for k_neighbors in k_neighbors_all:\n",
    "        buffer = pickle.load(open('data/athens/athens_buff_k' + str(k_neighbors) + '.pickle', \"rb\"))\n",
    "        buffer_dis = pickle.load(open('data/athens/athens_buff_dis_k' + str(k_neighbors) + '.pickle', \"rb\"))\n",
    "        buffer_dis = np.delete(buffer_dis, 0, 1)\n",
    "\n",
    "        # rp\n",
    "        db_rp = rp_db(gdf1, buffer_dis, labels_binary, T)\n",
    "        fw.write('rp,,' + str(k_neighbors) + ',' + str(db_rp[0]) + ',' + str(db_rp[1]) + ',' + str(db_rp[2]) + '\\n')\n",
    "        print('db_rp:', db_rp[0], db_rp[1], db_rp[2])\n",
    "        \n",
    "        # lw\n",
    "        db_lw = lw_db(gdf2, buffer, labels_binary, T)\n",
    "        fw.write('lw,,' + str(k_neighbors) + ',' + str(db_lw[0]) + ',' + str(db_lw[1]) + ',' + str(db_lw[2]) + '\\n')\n",
    "        print('db_lw:', db_lw[0], db_lw[1], db_lw[2])\n",
    "        \n",
    "        # gm\n",
    "        for eps in eps_all:\n",
    "            prob = pd.read_csv('data/athens/sols/athens_prob_eps' + str(eps) + \"_k\" + str(k_neighbors) + '.csv', header=None, index_col=0)\n",
    "            db_gm = gm_db(gdf2, prob, buffer, labels_binary, T)\n",
    "            fw.write('gm,' + str(eps) + ',' + str(k_neighbors) + ',' + str(db_gm[0]) + ',' + str(db_gm[1]) + ',' + str(db_gm[2]) + '\\n')\n",
    "            print('db_gm:', db_gm[0], db_gm[1], db_gm[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
